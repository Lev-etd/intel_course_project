{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d9de615",
   "metadata": {},
   "source": [
    "## OpenFace features + classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa0ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e853a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'D:\\Users\\amira\\Documents\\datasets\\emotions\\AudioVideo\\openface'\n",
    "IMG_SIZE = 224\n",
    "\n",
    "emotion_to_index = {'Angry':0, 'Disgust':1, 'Fear':2, 'Happy':3, 'Neutral':4, 'Sad':5, 'Surprise':6}\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e78266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42508450500b40549c997976e7573c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60fa1736fdde493ca0bd96790b235855",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f59b72b76148d0a7d0ff7cfa8404ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abc63e8581d4c409ba88ebcfdaae14c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aef8139256e4d88a66b8a3518819b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf4d99a35085488da50ade0e9a109453",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a01d3199e1df4eec807974eb2d9788e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 1316) (773,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebad2f8921e4e97adf84b51968d0882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ff0f09571a47989ae4cb97484a4ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4c4e4a21c74b96a2cc52d5d2102f4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9e663ed7d604c92a3d23f33c34f52a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77fe292c4904153a3bd397772477e43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4374cb2582764a22ac5558417200d27e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6faca94080448068b5e1e6e72b5c470",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 1316) (383,)\n"
     ]
    }
   ],
   "source": [
    "def create_openface_dataset(data_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    for class_name in emotion_to_index:\n",
    "        for filename in tqdm(os.listdir(os.path.join(data_dir,class_name))):\n",
    "            fn=os.path.splitext(filename)[0] # goes through files names without extension\n",
    "            if 'of_details' not in fn:\n",
    "                openface_df = pd.read_csv(os.path.join(data_dir,class_name,filename))\n",
    "                # fill zeroes with mean values on frames where openface failed to detect faces \n",
    "                openface_df.loc[openface_df[' success'] == 0] = openface_df.loc[openface_df[' success'] == 0].replace(0, openface_df.loc[openface_df[' success'] == 1].mean())\n",
    "                # remove some irrelevant columns\n",
    "                openface_df = openface_df.loc[:, ~openface_df.columns.isin(['frame', ' face_id', ' timestamp', ' confidence', ' success'])]\n",
    "\n",
    "                total_features=None\n",
    "                mean_features = (np.mean(openface_df, axis=0))\n",
    "                std_features = (np.std(openface_df, axis=0))\n",
    "                max_features = (np.max(openface_df, axis=0))\n",
    "                min_features = (np.min(openface_df, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "                #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "                #feature=max_features\n",
    "\n",
    "                total_features=feature\n",
    "                \n",
    "                if total_features is not None:\n",
    "                    x.append(total_features)\n",
    "                    y.append(emotion_to_index[class_name])\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    print(x.shape,y.shape)\n",
    "    return x,y\n",
    "\n",
    "x_train_of, y_train_of = create_openface_dataset(os.path.join(DATA_DIR, 'Train_AFEW'))\n",
    "x_test_of, y_test_of = create_openface_dataset(os.path.join(DATA_DIR, 'Val_AFEW'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2948cd94",
   "metadata": {},
   "source": [
    "There are 24 videos from Train and 11 videos from Test where OpenFace completely failed to detect faces. In order to use normalization we have to get rid of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aead7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_x_train_of = np.isnan(x_train_of)\n",
    "of_has_faces_train = []\n",
    "\n",
    "for i in range(len(mask_x_train_of)):\n",
    "    of_has_faces_train.append((len(np.where(mask_x_train_of[i]==1)[0]) == 0))\n",
    "\n",
    "\n",
    "mask_x_test_of = np.isnan(x_test_of)\n",
    "of_has_faces_test = []\n",
    "\n",
    "for i in range(len(mask_x_test_of)):\n",
    "    of_has_faces_test.append((len(np.where(mask_x_test_of[i]==1)[0]) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "efb8d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm,metrics,preprocessing\n",
    "\n",
    "x_train_of_norm=preprocessing.normalize(x_train_of[of_has_faces_train],norm='l2')\n",
    "x_test_of_norm=preprocessing.normalize(x_test_of[of_has_faces_test],norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e6eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete accuracy: 0.34986945169712796\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "np.random.seed(1)\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=1000,use_label_encoder=False)\n",
    "  \n",
    "xgb_clf.fit(x_train_of, y_train_of)\n",
    "y_pred_of = xgb_clf.predict(x_test_of)\n",
    "\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test_of, y_pred_of))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2669775",
   "metadata": {},
   "outputs": [],
   "source": [
    "of_proba = xgb_clf.predict_proba(x_test_of)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9de84ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_of_afew.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_name = 'xgb'\n",
    "MODEL2EMOTIW_FEATURES=model_name+'_of_afew.pickle' \n",
    "\n",
    "print(MODEL2EMOTIW_FEATURES)\n",
    "\n",
    "with open(MODEL2EMOTIW_FEATURES, 'wb') as handle:\n",
    "    pickle.dump(of_proba, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cd068",
   "metadata": {},
   "source": [
    "Accuracy is higher when passing all data to XGBoost and the same with and without normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fefe68",
   "metadata": {},
   "source": [
    "## Enet + OpenFace Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c217c9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_afew_torch.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_name = 'enet_b0_8'\n",
    "MODEL2EMOTIW_FEATURES=model_name+'_afew_torch.pickle' \n",
    "\n",
    "print(MODEL2EMOTIW_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "89c2601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773 383\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL2EMOTIW_FEATURES, 'rb') as handle:\n",
    "    filename2features_train,filename2features_val=pickle.load(handle)\n",
    "print(len(filename2features_train),len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcfe0a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c44e17681345c3ab4ef656a0413e51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e9731513d324b3bac4a344d111816d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14dd79eccc6c495b9c9ba230e12eff9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59cc5c93c2e4045b7c8bfb858238dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60ba180711b2449f90ae0b0e2dc7b2a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153c4ebcaa4a4bc5a5217db6beec7c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6335c81fee194040ae826b111689c760",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 5120) (773,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36d039d96ef4f83936fe457e922b49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af01bb5a8e8c4f1287e85c2b0852cf25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c33ddc743ce4bd0b111ef1eeeb43905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "837978a8b5eb4a968b8b8be848dcd05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f80ca4ad22354c33bc1efd2459eb6566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc32268c515245a7b73d4babd5e41e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e3066230b284d359d9f2450982433eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 5120) (383,)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(filename2features,data_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    has_faces=[]\n",
    "    ind=0\n",
    "    for class_name in emotion_to_index:\n",
    "        for filename in tqdm(os.listdir(os.path.join(data_dir,class_name))):\n",
    "            fn=os.path.splitext(filename)[0] # goes through files names\n",
    "            if not fn in filename2features:\n",
    "                continue\n",
    "            features=filename2features[fn]\n",
    "            total_features=None\n",
    "            #print(len(features))\n",
    "            if True:\n",
    "                if len(features[0])!=0:\n",
    "                    cur_features=features[0][features[-1]==1]\n",
    "                #print(prev,features.shape)\n",
    "            else:\n",
    "                cur_features=features[0]\n",
    "            if len(cur_features)==0:\n",
    "                has_faces.append(0)\n",
    "                total_features=np.zeros_like(feature)\n",
    "            else:\n",
    "                has_faces.append(1)\n",
    "                #mean_features=features.mean(axis=0)\n",
    "                mean_features = (np.mean(cur_features, axis=0))\n",
    "                std_features = (np.std(cur_features, axis=0))\n",
    "                max_features = (np.max(cur_features, axis=0))\n",
    "                min_features = (np.min(cur_features, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "                #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "                #feature=max_features\n",
    "\n",
    "                total_features=feature\n",
    "            \n",
    "            if total_features is not None:\n",
    "                x.append(total_features)\n",
    "                y.append(emotion_to_index[class_name])\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    has_faces=np.array(has_faces)\n",
    "    print(x.shape,y.shape)\n",
    "    return x,y,has_faces\n",
    "\n",
    "x_train_enet, y_train_enet, has_faces_train = create_dataset(filename2features_train, os.path.join(DATA_DIR, 'Train_AFEW'))\n",
    "x_test_enet, y_test_enet, has_faces_test = create_dataset(filename2features_val, os.path.join(DATA_DIR, 'Val_AFEW'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cff819db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm,metrics,preprocessing\n",
    "\n",
    "x_train_enet_norm=preprocessing.normalize(x_train_enet,norm='l2')\n",
    "x_test_enet_norm=preprocessing.normalize(x_test_enet,norm='l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df7ac17",
   "metadata": {},
   "source": [
    "Concatenate features without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "48e4b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = np.concatenate((x_train_enet_norm,x_train_of),axis=1)\n",
    "x_test_cat = np.concatenate((x_test_enet_norm,x_test_of),axis=1)\n",
    "\n",
    "valid_train = np.multiply(has_faces_train, of_has_faces_train)\n",
    "valid_test = np.multiply(has_faces_test, of_has_faces_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767c1fb5",
   "metadata": {},
   "source": [
    "Concatenate normalized features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3b5c550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat_norm = np.concatenate((x_train_enet_norm[of_has_faces_train],x_train_of_norm),axis=1)\n",
    "x_test_cat_norm = np.concatenate((x_test_enet_norm[of_has_faces_test],x_test_of_norm),axis=1)\n",
    "y_train_cat_norm = y_train_enet[of_has_faces_train]\n",
    "y_test_cat_norm = y_test_enet[of_has_faces_test]\n",
    "\n",
    "valid_train_cat_norm = np.multiply(has_faces_train[of_has_faces_train], np.array(of_has_faces_train)[of_has_faces_train])\n",
    "valid_test_cat_norm = np.multiply(has_faces_test[of_has_faces_test], np.array(of_has_faces_test)[of_has_faces_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e343311",
   "metadata": {},
   "source": [
    "Concatenated features from Enet and OpenFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60280513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete accuracy: 0.5248041775456919\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "np.random.seed(1)\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=2000,use_label_encoder=False)\n",
    "\n",
    "xgb_clf.fit(x_train_cat, y_train_enet)\n",
    "y_pred = xgb_clf.predict(x_test_cat)\n",
    "\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test_enet, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125e66",
   "metadata": {},
   "source": [
    "Concatenated normalized features but only that have faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "15fc0370",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5806451612903226\n",
      "Complete accuracy: 0.5639686684073107\n"
     ]
    }
   ],
   "source": [
    "svc_clf = svm.LinearSVC(C=1.5)\n",
    "\n",
    "svc_clf.fit(x_train_cat_norm, y_train_cat_norm)\n",
    "y_pred = svc_clf.predict(x_test_cat_norm)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_cat_norm, y_pred))\n",
    "# fill in with dummy values to get complete accuracy\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(np.append(y_test_cat_norm, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=-1)), \n",
    "np.append(y_pred, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f87f8e98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5698924731182796\n",
      "Complete accuracy: 0.5535248041775457\n"
     ]
    }
   ],
   "source": [
    "svc_clf = svm.SVC(C=2, kernel='linear', probability=True)\n",
    "\n",
    "svc_clf.fit(x_train_cat_norm, y_train_cat_norm)\n",
    "y_pred = svc_clf.predict(x_test_cat_norm)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_cat_norm, y_pred))\n",
    "# fill in with dummy values to get complete accuracy\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(np.append(y_test_cat_norm, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=-1)), \n",
    "np.append(y_pred, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "5e6a2b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5349462365591398\n",
      "Complete accuracy: 0.5195822454308094\n"
     ]
    }
   ],
   "source": [
    "rf_clf=RandomForestClassifier(n_estimators=2000,max_depth=10, n_jobs=-1)\n",
    "\n",
    "rf_clf.fit(x_train_cat_norm, y_train_cat_norm)\n",
    "y_pred = rf_clf.predict(x_test_cat_norm)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_cat_norm, y_pred))\n",
    "# fill in with dummy values to get complete accuracy\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(np.append(y_test_cat_norm, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=-1)), \n",
    "np.append(y_pred, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "3b22a821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5510752688172043\n",
      "Complete accuracy: 0.5352480417754569\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = xgb.XGBClassifier(n_estimators=1500,use_label_encoder=False)\n",
    "\n",
    "xgb_clf.fit(x_train_cat_norm, y_train_cat_norm)\n",
    "y_pred = xgb_clf.predict(x_test_cat_norm)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_cat_norm, y_pred))\n",
    "# fill in with dummy values to get complete accuracy\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(np.append(y_test_cat_norm, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=-1)), \n",
    "np.append(y_pred, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=100))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "f7e87f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5510752688172043\n",
      "Complete accuracy: 0.5352480417754569\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(estimators=[('svc', svc_clf), ('rf', rf_clf), ('xgb', xgb_clf)], voting='soft')\n",
    "vote_clf.fit(x_train_cat_norm, y_train_cat_norm)\n",
    "y_pred = vote_clf.predict(x_test_cat_norm)\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_cat_norm, y_pred))\n",
    "# fill in with dummy values to get complete accuracy\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(np.append(y_test_cat_norm, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=-1)), \n",
    "np.append(y_pred, np.full((len(y_test_enet)-len(y_test_cat_norm)), fill_value=100))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe3aa23",
   "metadata": {},
   "source": [
    "Concatenated features but only that have faces in Openface (without normalization) and Enet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "76acc4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.553763440860215\n",
      "Complete accuracy: 0.553763440860215\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=1500,use_label_encoder=False)\n",
    " \n",
    "xgb_clf.fit(x_train_cat[valid_train==1], y_train_enet[valid_train==1])\n",
    "y_pred = xgb_clf.predict(x_test_cat[valid_test==1])\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_enet[valid_test==1], y_pred))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test_enet[valid_test==1], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "770a7744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.543010752688172\n",
      "Complete accuracy: 0.543010752688172\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "rf_clf=RandomForestClassifier(n_estimators=2300,max_depth=12, n_jobs=-1)\n",
    "    \n",
    "rf_clf.fit(x_train_cat[valid_train==1], y_train_enet[valid_train==1])\n",
    "y_pred = rf_clf.predict(x_test_cat[valid_test==1])\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_enet[valid_test==1], y_pred))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test_enet[valid_test==1], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb93f3a",
   "metadata": {},
   "source": [
    "Due to different scale of features from Enet and OpenFace, LinearSVC failed to converge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d6d11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5645161290322581\n",
      "Complete accuracy: 0.5645161290322581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(estimators=[('rf', rf_clf), ('xgb', xgb_clf)], voting='soft')\n",
    "vote_clf.fit(x_train_cat[valid_train==1], y_train_enet[valid_train==1])\n",
    "y_pred = vote_clf.predict(x_test_cat[valid_test==1])\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_enet[valid_test==1], y_pred))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test_enet[valid_test==1], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1da7a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.553763440860215\n",
      "Complete accuracy: 0.553763440860215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "st_clf = StackingClassifier(estimators=[('rf', rf_clf), ('xgb', xgb_clf)])\n",
    "st_clf.fit(x_train_cat[valid_train==1], y_train_enet[valid_train==1])\n",
    "y_pred = st_clf.predict(x_test_cat[valid_test==1])\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test_enet[valid_test==1], y_pred))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test_enet[valid_test==1], y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ed3981b15a223883aee74f0ceebf90ae99ff8cc4fd329eb8565e2053aa83b18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
